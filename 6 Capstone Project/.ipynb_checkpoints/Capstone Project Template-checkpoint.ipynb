{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Warehouse to Analyze US Immigration Data\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The aim of this project is to model and create a analytics solution to help Data Analysts and Data Scientists to gather various insights from the wealth of data that is collected during the US immigration process.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "The goal of this project is to create a data warehouse which can be queried by Data Analysts using various tools and dashbards. This warehouse can be opened up for various independent vendors(such as travel agencies) who can gather various insights from the data with information related to international US visitors. \n",
    "\n",
    "Apache Spark has been used to gather/assess and clean the data, which will then be saved in Amazon S3 buckets. This transformed data will then be saved as parquet files, which can be loaded into various types of databases and used as an input for various analytical tools.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "Following are the sources of data:\n",
    "\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. \n",
    "- World Temperature Data: This dataset came from Kaggle. This has information for cities/countries.\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft. This has information related to structure of the population for the US cities.\n",
    "- Airport Code Table: This is a simple table of airport codes and corresponding cities.\n",
    "- The I94_SAS_Labels_Descriptions.SAS file also has been provided. This describes the data in the I94 Immigration data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Gather Data using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Immigration Data (I94 Immigration Data)\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| cicid | Unique Identifier |\n",
    "| i94yr | Four digit year |\n",
    "| i94mon | Numeric month |\n",
    "| i94res | Country Code |\n",
    "| i94cit | Country Code |\n",
    "| i94port |\tPort Code |\n",
    "| arrdate |\tArrival Date |\n",
    "| i94mode |\tMode of travel |\n",
    "| i94addr |\tAddress provided |\n",
    "| depdate |\tDepature date |\n",
    "| i94bir | Age |\n",
    "| i94visa |\tVisa Code - 1 = Business / 2 = Pleasure / 3 = Student |\n",
    "| count | Used for summary statistics |\n",
    "| dtadfile | Date added to I-94 Files |\n",
    "| visapost | Department of State where where Visa was issued |\n",
    "| occup | Occupation that will be performed in U.S. |\n",
    "| entdepa |\tArrival Flag - admitted or paroled into the U.S. |\n",
    "| entdepd |\tDeparture Flag - Departed, lost I-94 or is deceased |\n",
    "| entdepu |\tUpdate Flag - Either apprehended, overstayed, adjusted to perm residence |\n",
    "| matflag |\tMatch flag - Match of arrival and departure records |\n",
    "| biryear |\tFour digit year of birth |\n",
    "| dtaddto |\tDate to which admitted to U.S. (allowed to stay until) |\n",
    "| gender | Gender |\n",
    "| insnum | INS number |\n",
    "| airline |\tAirline used to arrive in U.S. |\n",
    "| admnum | Admission Number |\n",
    "| fltno | Flight number of Airline used to arrive in U.S. |\n",
    "| visatype | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "immigration_df_spark.createOrReplaceTempView(\"immigration_table\")\n",
    "immigration_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Temperature Data\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| dt | Date |\n",
    "| AverageTemperature | Average temperature for the day |\n",
    "| AverageTemperatureUncertainty | Average temperature uncertaintly for the day |\n",
    "| City | City name |\n",
    "| Country | Country name |\n",
    "| Latitude | Latitude |\n",
    "| Longitude | Longitude |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df_spark = spark.read.csv(temperature_fname,header='true')\n",
    "temperature_df_spark.createOrReplaceTempView(\"temperature_table\")\n",
    "temperature_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "City Demographics Data\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| City | City Name |\n",
    "| State | State Name |\n",
    "| Median Age | Average age of the population |\n",
    "| Male Population | Male population in the city |\n",
    "| Female Population | Female population in the city |\n",
    "| Total Population | Total population in the city |\n",
    "| Number of Veterans | Population of veterans |\n",
    "| Foreign-born | Foreign born population |\n",
    "| Average Household Size | Average household Size |\n",
    "| State Code | State Code |\n",
    "| Race | Race |\n",
    "| Count | Count of Race |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_demographic_fname = 'us-cities-demographics.csv'\n",
    "demographics_df_spark = spark.read.csv(city_demographic_fname,sep=';',header='true')\n",
    "demographics_df_spark.createOrReplaceTempView(\"demographics_table\")\n",
    "demographics_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Airport Codes Data\n",
    "\n",
    "Data dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| ident | Airport code |\n",
    "| type | Type of airport |\n",
    "| name | Name of airport |\n",
    "| elevation_ft | Elevation of airport |\n",
    "| continent | Continent where airport is located |\n",
    "| iso_country | Country Code |\n",
    "| iso_region | Region Code |\n",
    "| municipality | Municipality | \n",
    "| gps_code | GPS Code |\n",
    "| iata_code | IATA Code |\n",
    "| local_code| Local Code |\n",
    "| coordinates | GPS Coordinates |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_fname = 'airport-codes_csv.csv'\n",
    "airport_codes_df_spark = spark.read.csv(airport_codes_fname,sep=',',header='true')\n",
    "airport_codes_df_spark.createOrReplaceTempView(\"airport_codes_table\")\n",
    "airport_codes_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Gather Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to get data using the 'I94_SAS_Labels_Descriptions.SAS' file\n",
    "def get_i94_sas_labels(inputStr,column_1,column_2):\n",
    "    \"\"\"\n",
    "        This function parses the data in the file 'I94_SAS_Labels_Descriptions.SAS' and retuns a Pandas dataframe based on the input provided.\n",
    "        \n",
    "        The input passed to this function are:\n",
    "        1. inputStr - input string which looks for the identifier based on which the data is gathered. \n",
    "           eg. if $i94prtl is the passed, port inforamation from the file is retreived and stored as a pandas dataframe.\n",
    "        2. column_1 - First Field name for the dataframe returned.\n",
    "        3. column_2 - Second Field name for the dataframe returned.\n",
    "        \n",
    "        The output returned by this function is a Pandas dataframe.\n",
    "        \"\"\"    \n",
    "    i=0\n",
    "    startLine = 0\n",
    "    endLine = 0\n",
    "    keyWordFound = 0    \n",
    "    keyWord = inputStr\n",
    "    print('Searching for:'+keyWord)\n",
    "    with open(\"I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "        for line in f:\n",
    "            i = i + 1\n",
    "            if(len((line.split(\" \"))) < 1 and (line != ';\\n')):\n",
    "                continue\n",
    "            if(line.split(\" \")[0] != '\\n'):\n",
    "                if(keyWord+'\\n' in line.split(\" \")):\n",
    "                    startLine = i+1\n",
    "                    keyWordFound = 1\n",
    "                if((line.split(\" \")[-1] == ';\\n') and keyWordFound == 1):\n",
    "                    endLine = i\n",
    "                    keyWordFound = 0            \n",
    "            if((line == ';\\n') and keyWordFound == 1):\n",
    "                print(line.split(\" \")[0])\n",
    "                endLine = i-1\n",
    "                keyWordFound = 0\n",
    "    \n",
    "    with open(\"I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "        i=0\n",
    "        list = []\n",
    "        for line in f:\n",
    "            i = i + 1\n",
    "            if(i>=startLine and i<=endLine):\n",
    "                line = line.replace('\\t', '').replace('\\n', '').replace('\\'','').replace(';','')\n",
    "                list.append(line.split('='))\n",
    "    \n",
    "    df = pd.DataFrame(list, columns =[column_1, column_2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Get country and code mapping data\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| Country_Id | Country Identifier |\n",
    "| Country | Country Name | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for:i94cntyl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Id</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Id                                            Country\n",
       "0       582     MEXICO Air Sea, and Not Reported (I-94, no l...\n",
       "1       236                                         AFGHANISTAN\n",
       "2       101                                             ALBANIA\n",
       "3       316                                             ALGERIA\n",
       "4       102                                             ANDORRA"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_mapping_df = get_i94_sas_labels('i94cntyl','Country_Id','Country')\n",
    "country_mapping_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Get port and code mapping data\n",
    "\n",
    "Data dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| Port_Id | Port Identifier |\n",
    "| Port | Port Name | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_mapping_df = get_i94_sas_labels('$i94prtl','Port_Id','Port')\n",
    "port_mapping_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Get Immigration mode and code mapping data\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| Mode_Id | Immigration mode Identifier |\n",
    "| Mode | Immigration Mode | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for:i94model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode_Id</th>\n",
       "      <th>Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mode_Id            Mode\n",
       "0      1              Air\n",
       "1      2              Sea\n",
       "2      3             Land\n",
       "3      9    Not reported "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_mode_df = get_i94_sas_labels('i94model','Mode_Id','Mode')\n",
    "immigration_mode_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Get State and state code mapping data\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Field | Description|\n",
    "| --- | --- |\n",
    "| State_Id | State Identifier |\n",
    "| State | State Name | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for:i94addrl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Id</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State_Id       State\n",
       "0       AL     ALABAMA\n",
       "1       AK      ALASKA\n",
       "2       AZ     ARIZONA\n",
       "3       AR    ARKANSAS\n",
       "4       CA  CALIFORNIA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_code_df = get_i94_sas_labels('i94addrl','State_Id','State')\n",
    "state_code_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the Immigration Data\n",
    "\n",
    "- Data type and format for the date fields need to be changed - arrdate, depdate, dtafile, dtaddto\n",
    "- The data source has 3,096,313 entries\n",
    "- No duplicate entries found based on cicid\n",
    "- All entries in the immigration data source has valid i94port identifiers\n",
    "- All entries in the immigration data source has valid i94res identifiers\n",
    "- There are 239 entries with i94mode as null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid|i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum        |fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|6.0  |2016.0|4.0   |692.0 |692.0 |XXX    |20573.0|null   |null   |null   |37.0  |2.0    |1.0  |null    |null    |null |T      |null   |U      |null   |1979.0 |10282016|null  |null  |null   |1.897628485E9 |null |B2      |\n",
      "|7.0  |2016.0|4.0   |254.0 |276.0 |ATL    |20551.0|1.0    |AL     |null   |25.0  |3.0    |1.0  |20130811|SEO     |null |G      |null   |Y      |null   |1991.0 |D/S     |M     |null  |null   |3.73679633E9  |00296|F1      |\n",
      "|15.0 |2016.0|4.0   |101.0 |101.0 |WAS    |20545.0|1.0    |MI     |20691.0|55.0  |2.0    |1.0  |20160401|null    |null |T      |O      |null   |M      |1961.0 |09302016|M     |null  |OS     |6.66643185E8  |93   |B2      |\n",
      "|16.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |MA     |20567.0|28.0  |2.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |1988.0 |09302016|null  |null  |AA     |9.246846133E10|00199|B2      |\n",
      "|17.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |MA     |20567.0|4.0   |2.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |2012.0 |09302016|null  |null  |AA     |9.246846313E10|00199|B2      |\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#immigration_df_spark.printSchema()\n",
    "immigration_df_spark.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Count|\n",
      "+-------+\n",
      "|3096313|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the number of entires in the immigration data source\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    count(*) as Count\n",
    "    FROM immigration_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|cicid|Count|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate entries based on cicid\n",
    "spark.sql(\"\"\"\n",
    "    SELECT cicid, count(*) as Count\n",
    "    FROM immigration_table\n",
    "    GROUP BY cicid\n",
    "    HAVING Count>1    \n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "|  239|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if entries in the immigration data source has null arrival mode identifiers\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    count(*) as Count\n",
    "    FROM immigration_table\n",
    "    WHERE i94mode is null\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#immigration_df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the Temperature Data\n",
    "\n",
    "- The data source has 8,599,212 entries\n",
    "- 364,130 entries have 'null' entries for average temperature\n",
    "- Date type of AverateTemperature and AverageTemperatureUncertainty is String.\n",
    "- This dataset has the data only upt0 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df_spark.printSchema()\n",
    "#temperature_df_spark.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Count|\n",
      "+-------+\n",
      "|8599212|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the number of entires in the temperature data source\n",
    "# temperature_df_spark.count()\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    count(*) as Count\n",
    "    FROM temperature_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Count|\n",
      "+------+\n",
      "|364130|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# entries with null values for average temperature\n",
    "# temperature_df_spark.filter(temperature_df_spark.AverageTemperature.isNull()).count()\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    count(*) as Count\n",
    "    FROM temperature_table\n",
    "    WHERE averageTemperature is null\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|   Country|        City|Count|\n",
      "+----------+------------+-----+\n",
      "| Mauritius|  Port Louis| 1039|\n",
      "|   Reunion| Saint Denis| 1039|\n",
      "|Madagascar|Fianarantsoa| 1036|\n",
      "|Mozambique|      Nacala|  958|\n",
      "|Madagascar|   Antsirabe|  958|\n",
      "+----------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of entries for countries\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    Country, City, count(*) as Count\n",
    "    FROM temperature_table    \n",
    "    WHERE averageTemperature is null\n",
    "    GROUP BY Country, City\n",
    "    ORDER BY Count DESC\n",
    "    \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Year|count(1)|\n",
      "+----+--------+\n",
      "|2013|   28520|\n",
      "|2012|   42120|\n",
      "|2011|   42120|\n",
      "|2010|   42120|\n",
      "|2009|   42120|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# entries for different years\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    substr(dt,1,4) as Year, count(*)\n",
    "    FROM temperature_table\n",
    "    WHERE AverageTemperature is not null\n",
    "    group by Year\n",
    "    order by Year desc\n",
    "    \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show a few entries\n",
    "temperature_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the City Demographics Data\n",
    "\n",
    "- The data source has 2891 entries\n",
    "- Field names have spaces\n",
    "- Few rows have NULL values for - 'Male Population', 'Female Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size'.\n",
    "- The dataset has multiple entries for the different 'Race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_df_spark.printSchema()\n",
    "#temperature_df_spark.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "| 2891|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the number of entries in the city demographics data source\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    count(*) as Count\n",
    "    FROM demographics_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "|summary|   City|    State|       Median Age|   Male Population| Female Population|  Total Population|Number of Veterans|      Foreign-born|Average Household Size|State Code|                Race|             Count|\n",
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "|  count|   2891|     2891|             2891|              2888|              2888|              2891|              2878|              2878|                  2875|      2891|                2891|              2891|\n",
      "|   mean|   null|     null|35.49488066413016| 97328.42624653739|101769.63088642659|198966.77931511588| 9367.832522585128|40653.598679638635|     2.742542608695655|      null|                null| 48963.77447250087|\n",
      "| stddev|   null|     null|4.401616730099886|216299.93692873296|231564.57257148277| 447555.9296335903| 13211.21992386408| 155749.1036650984|    0.4332910878973046|      null|                null|144385.58856460615|\n",
      "|    min|Abilene|  Alabama|             22.9|            100135|            100260|            100247|             10001|             10024|                   2.0|        AK|American Indian a...|            100055|\n",
      "|    max|   Yuma|Wisconsin|             70.5|             99967|             99430|             99897|              9988|              9929|                  4.98|        WI|               White|             99948|\n",
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe the demographics data source\n",
    "demographics_df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "|State|City|Count|\n",
      "+-----+----+-----+\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the number of entries in the city demographics data source\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    State, City, Count(*) as Count\n",
    "    FROM demographics_table\n",
    "    GROUP BY State, City\n",
    "    HAVING Count >5\n",
    "    \"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the Airport Codes Data\n",
    "\n",
    "- The data source has 55075 entries\n",
    "- There are seven distinct types of aiports\n",
    "- iso_region is a combination of iso_country and state/region code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_df_spark.printSchema()\n",
    "#airport_codes_df_spark.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "|ident|type         |name                              |elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|coordinates                          |\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "|00A  |heliport     |Total Rf Heliport                 |11          |NA       |US         |US-PA     |Bensalem    |00A     |null     |00A       |-74.93360137939453, 40.07080078125   |\n",
      "|00AA |small_airport|Aero B Ranch Airport              |3435        |NA       |US         |US-KS     |Leoti       |00AA    |null     |00AA      |-101.473911, 38.704022               |\n",
      "|00AK |small_airport|Lowell Field                      |450         |NA       |US         |US-AK     |Anchor Point|00AK    |null     |00AK      |-151.695999146, 59.94919968          |\n",
      "|00AL |small_airport|Epps Airpark                      |820         |NA       |US         |US-AL     |Harvest     |00AL    |null     |00AL      |-86.77030181884766, 34.86479949951172|\n",
      "|00AR |closed       |Newport Hospital & Clinic Heliport|237         |NA       |US         |US-AR     |Newport     |null    |null     |null      |-91.254898, 35.6087                  |\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_df_spark.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------+--------------------+------------------+---------+-----------+----------+---------------+--------------------+---------+-------------------+--------------------+\n",
      "|summary|               ident|         type|                name|      elevation_ft|continent|iso_country|iso_region|   municipality|            gps_code|iata_code|         local_code|         coordinates|\n",
      "+-------+--------------------+-------------+--------------------+------------------+---------+-----------+----------+---------------+--------------------+---------+-------------------+--------------------+\n",
      "|  count|               55075|        55075|               55075|             48069|    55075|      55075|     55075|          49399|               41030|     9189|              28686|               55075|\n",
      "|   mean|2.3873375337777779E8|         null|                null|1240.7896773388254|     null|       null|      null|           null|2.1920446610204083E8|      0.0|8.580556178571428E7|                null|\n",
      "| stddev| 9.492375382267495E8|         null|                null|1602.3634593484142|     null|       null|      null|           null|   9.1123224377024E8|      0.0|5.747026415216715E8|                null|\n",
      "|    min|                 00A|  balloonport|\"\"\"Der Dingel\"\" A...|                -1|       AF|         AD|     AD-04|'S Gravenvoeren|                0000|        -|                  -|-0.00472200009971...|\n",
      "|    max|                spgl|small_airport|Çá¸¾á¸á¸ á¸®á¸...|               999|       SA|         ZZ|    ZZ-U-A|        Å½ocene|                ZYYY|      ZZV|                ZZV|99.9555969238, 8....|\n",
      "+-------+--------------------+-------------+--------------------+------------------+---------+-----------+----------+---------------+--------------------+---------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "|55075|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the iso_region is a combination of iso_country and state/region code\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    count(*) as Count\n",
    "    FROM airport_codes_table\n",
    "    WHERE iso_country = substr(iso_region,1,2)\n",
    "    \"\"\").show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the Country Codes Data (source - I94_SAS_Labels_Descriptions.SAS)\n",
    "\n",
    "- The data source has 289 entries\n",
    "- Country_Id data type is not consistent with the immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289 entries, 0 to 288\n",
      "Data columns (total 2 columns):\n",
      "Country_Id    289 non-null object\n",
      "Country       289 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Id</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Id                                            Country\n",
       "0       582     MEXICO Air Sea, and Not Reported (I-94, no l...\n",
       "1       236                                         AFGHANISTAN\n",
       "2       101                                             ALBANIA\n",
       "3       316                                             ALGERIA\n",
       "4       102                                             ANDORRA"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_mapping_df.info()\n",
    "country_mapping_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the Port Codes Data (source - I94_SAS_Labels_Descriptions.SAS)\n",
    "\n",
    "- The data source has 661 entries\n",
    "- 1 entry has a null value\n",
    "- Port comprises of Port Name and the State Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 661 entries, 0 to 660\n",
      "Data columns (total 2 columns):\n",
      "Port_Id    661 non-null object\n",
      "Port       660 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port_Id</th>\n",
       "      <th>Port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Port_Id                          Port\n",
       "0     ALC        ALCAN, AK             \n",
       "1     ANC        ANCHORAGE, AK         \n",
       "2     BAR  BAKER AAF - BAKER ISLAND, AK\n",
       "3     DAC        DALTONS CACHE, AK     \n",
       "4     PIZ    DEW STATION PT LAY DEW, AK"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_mapping_df.info()\n",
    "port_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port_Id</th>\n",
       "      <th>Port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Port_Id  Port\n",
       "660          None"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_mapping_df[port_mapping_df.Port.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the Immigration Mode (source - I94_SAS_Labels_Descriptions.SAS)\n",
    "\n",
    "- The data source has 4 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      "Mode_Id    4 non-null object\n",
      "Mode       4 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 144.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode_Id</th>\n",
       "      <th>Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mode_Id            Mode\n",
       "0      1              Air\n",
       "1      2              Sea\n",
       "2      3             Land\n",
       "3      9    Not reported "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_mode_df.info()\n",
    "immigration_mode_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Assess the State Code data (source - I94_SAS_Labels_Descriptions.SAS)\n",
    "\n",
    "- The data source has 55 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55 entries, 0 to 54\n",
      "Data columns (total 2 columns):\n",
      "State_Id    55 non-null object\n",
      "State       55 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 960.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Id</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State_Id       State\n",
       "0       AL     ALABAMA\n",
       "1       AK      ALASKA\n",
       "2       AZ     ARIZONA\n",
       "3       AR    ARKANSAS\n",
       "4       CA  CALIFORNIA"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_code_df.info()\n",
    "state_code_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the Immigration Data\n",
    "\n",
    "- Data type and format for the date fields need to be changed - arrdate, depdate, dtafile, dtaddto\n",
    "- Removed entries with i94mode with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+----------+--------+-----+-------+-------+-------+-------+-------+----------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|count|  dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|   dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+----------+--------+-----+-------+-------+-------+-------+-------+----------+------+------+-------+--------------+-----+--------+\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|2016-04-07|    1.0|     AL|      null|  25.0|    3.0|  1.0|2013-08-11|     SEO| null|      G|   null|      Y|   null| 1991.0|      null|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|2016-04-01|    1.0|     MI|2016-08-25|  55.0|    2.0|  1.0|2016-04-01|    null| null|      T|      O|   null|      M| 1961.0|2016-09-30|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|2016-04-01|    1.0|     MA|2016-04-23|  28.0|    2.0|  1.0|2016-04-01|    null| null|      O|      O|   null|      M| 1988.0|2016-09-30|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|2016-04-01|    1.0|     MA|2016-04-23|   4.0|    2.0|  1.0|2016-04-01|    null| null|      O|      O|   null|      M| 2012.0|2016-09-30|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|2016-04-01|    1.0|     MI|2016-04-11|  57.0|    1.0|  1.0|2016-04-01|    null| null|      O|      O|   null|      M| 1959.0|2016-09-30|  null|  null|     AZ|9.247103803E10|00602|      B1|\n",
      "+-----+------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+----------+--------+-----+-------+-------+-------+-------+-------+----------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Correct the date formats for the fields - arrdate, depdate and dtaddto\n",
    "cleaned_immigration_df_spark = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    cicid\n",
    "    ,i94yr \n",
    "    ,i94mon\n",
    "    ,i94cit\n",
    "    ,i94res\n",
    "    ,i94port\n",
    "    ,date_add('1960-01-01',arrdate) as arrdate\n",
    "    ,i94mode\n",
    "    ,i94addr\n",
    "    ,date_add('1960-01-01',depdate) as depdate\n",
    "    ,i94bir\n",
    "    ,i94visa\n",
    "    ,count\n",
    "    ,to_date(substring(dtadfile,1,4) || '-' || substring(dtadfile,5,2) || '-' || substring(dtadfile,7,2)) as dtadfile\n",
    "    ,visapost\n",
    "    ,occup\n",
    "    ,entdepa\n",
    "    ,entdepd\n",
    "    ,entdepu\n",
    "    ,matflag\n",
    "    ,biryear\n",
    "    ,to_date(substring(dtaddto,5,4) || '-' || substring(dtaddto,1,2) || '-' || substring(dtaddto,3,2)) as dtaddto \n",
    "    ,gender\n",
    "    ,insnum\n",
    "    ,airline\n",
    "    ,admnum        \n",
    "    ,fltno\n",
    "    ,visatype\n",
    "    FROM immigration_table\n",
    "    WHERE i94mode IS NOT NULL\n",
    "    \"\"\")\n",
    "cleaned_immigration_df_spark.createOrReplaceTempView(\"cleaned_immigration_table\")\n",
    "cleaned_immigration_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: date (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: date (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_immigration_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the Temperature Data\n",
    "\n",
    "- Change the data type for the temperature fields to float\n",
    "- Remove entries with NULL values for AverageTemperature\n",
    "- Aggregate the entries per City and Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change the data types\n",
    "cleaned_temperature_df_spark = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    City\n",
    "    ,Country\n",
    "    ,Latitude\n",
    "    ,Longitude\n",
    "    ,avg(cast(AverageTemperature as float)) AverageTemperature\n",
    "    ,avg(cast(AverageTemperatureUncertainty as float)) AverageTemperatureUncertainty\n",
    "    FROM temperature_table\n",
    "    WHERE \n",
    "    AverageTemperature IS NOT NULL\n",
    "    GROUP BY \n",
    "    City\n",
    "    ,Country\n",
    "    ,Latitude\n",
    "    ,Longitude\n",
    "    \"\"\")\n",
    "cleaned_temperature_df_spark.createOrReplaceTempView(\"cleaned_temperature_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+---------+------------------+-----------------------------+\n",
      "|    City|    Country|Latitude|Longitude|AverageTemperature|AverageTemperatureUncertainty|\n",
      "+--------+-----------+--------+---------+------------------+-----------------------------+\n",
      "|  Abohar|      India|  29.74N|   73.85E|24.753021123943796|           0.7542563609732382|\n",
      "|    Aden|      Yemen|  13.66N|   45.41E| 25.54778724600841|           0.9774613979558452|\n",
      "| Apodaca|     Mexico|  26.52N|  100.30W|22.018180757560987|           0.8791619677371627|\n",
      "|   Apopa|El Salvador|  13.66N|   90.00W| 25.36419148467728|           0.8325436019078251|\n",
      "|Belgorod|     Russia|  50.63N|   36.76E|  6.08863708202085|           1.4257706879359857|\n",
      "+--------+-----------+--------+---------+------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_temperature_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_temperature_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the City Demographics Data\n",
    "\n",
    "- The dataset has multiple entries for the different 'Race'. Seperate columns with the counts of the RACE are created.\n",
    "- The data types for numeric fields have been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createRaceDemographics(columnName, race):\n",
    "    \"\"\"\n",
    "        This function reads data from the 'demographics_table' (demographics_df_spark) Spark Dataframe \n",
    "        and returns a Spark Dataframe with demographic data for a particular race. These Race specific\n",
    "        dataframes can then be used to transform the 'demographics' dataframe to have the counts for \n",
    "        the different races in a single row rather than multiple rows.\n",
    "        \n",
    "        The input passed to this function are:\n",
    "        1. columnName - Field name which will store the number of people of a particular race.           \n",
    "        2. race - The race for this the Dataframe is to be created.\n",
    "        \n",
    "        The output returned by this function is a Spark dataframe and table which can be queried using SQL.\n",
    "        \"\"\" \n",
    "    raceDemograhpics_df = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "        City,\n",
    "        State,\n",
    "        cast(Count as int) as {}\n",
    "        FROM demographics_table\n",
    "        WHERE Race = '{}'\n",
    "        \"\"\".format(columnName,race))\n",
    "    raceDemograhpics_df.createOrReplaceTempView(\"{}_demographics_table\".format(columnName))\n",
    "    \n",
    "\n",
    "createRaceDemographics('Black','Black or African-American')\n",
    "createRaceDemographics('Hispanic','Hispanic or Latino')\n",
    "createRaceDemographics('White','White')\n",
    "createRaceDemographics('Asian','Asian')\n",
    "createRaceDemographics('Native','American Indian and Alaska Native')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------------+-------------------+----------------+----------------+-----------------+\n",
      "|         City|      State|State_Code|Median_Age|Male_Population|Female_Population|Total_Population|Number_Of_Veterans|Foreign_Born|Average_Household_Size|Black_Population|Hispanic_Population|White_Population|Asian_Population|Native_Population|\n",
      "+-------------+-----------+----------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------------+-------------------+----------------+----------------+-----------------+\n",
      "|     Gulfport|Mississippi|        MS|        35|          33108|            38764|           71872|              6646|        3072|                     2|           27799|               4247|           42870|            1723|             null|\n",
      "|Ellicott City|   Maryland|        MD|        42|          34406|            36526|           70932|              3856|       17587|                     2|            6089|               1602|           43537|           22551|              396|\n",
      "|Santa Barbara| California|        CA|        37|          45068|            46784|           91852|              4518|       19441|                     2|            2013|              31102|           73659|            4964|             1560|\n",
      "|    Rockville|   Maryland|        MD|        38|          31205|            35793|           66998|              1990|       25047|                     2|            7533|               9197|           41692|           17370|              594|\n",
      "|      Danbury|Connecticut|        CT|        37|          43435|            41227|           84662|              3752|       25675|                     2|            8454|              25145|           55917|            7350|             1086|\n",
      "+-------------+-----------+----------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------------+-------------------+----------------+----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_demographics_df_spark = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "    D.City\n",
    "    ,D.State\n",
    "    ,D.`State Code` as State_Code    \n",
    "    ,cast(D.`Median Age` as int) as Median_Age\n",
    "    ,cast(D.`Male Population`as int) as Male_Population\n",
    "    ,cast(D.`Female Population` as int) as Female_Population\n",
    "    ,cast(D.`Total Population` as int) as Total_Population\n",
    "    ,cast(D.`Number of Veterans` as int) as Number_Of_Veterans\n",
    "    ,cast(D.`Foreign-born` as int) as Foreign_Born\n",
    "    ,cast(D.`Average Household Size` as int) as Average_Household_Size\n",
    "    ,B.Black as Black_Population\n",
    "    ,H.Hispanic as Hispanic_Population\n",
    "    ,W.White as White_Population\n",
    "    ,A.Asian as Asian_Population\n",
    "    ,N.Native as Native_Population\n",
    "    FROM demographics_table D \n",
    "    LEFT JOIN black_demographics_table B\n",
    "    ON (D.City = B.City AND D.State = B.State)\n",
    "    LEFT JOIN hispanic_demographics_table H\n",
    "    ON (D.City = H.City AND D.State = H.State)\n",
    "    LEFT JOIN white_demographics_table W\n",
    "    ON (D.City = W.City AND D.State = W.State)\n",
    "    LEFT JOIN asian_demographics_table A\n",
    "    ON (D.City = A.City AND D.State = A.State)\n",
    "    LEFT JOIN native_demographics_table N\n",
    "    ON (D.City = N.City AND D.State = N.State)\n",
    "    \"\"\")\n",
    "cleaned_demographics_df_spark.createOrReplaceTempView(\"cleaned_demographics_table\")\n",
    "cleaned_demographics_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Median_Age: integer (nullable = true)\n",
      " |-- Male_Population: integer (nullable = true)\n",
      " |-- Female_Population: integer (nullable = true)\n",
      " |-- Total_Population: integer (nullable = true)\n",
      " |-- Number_Of_Veterans: integer (nullable = true)\n",
      " |-- Foreign_Born: integer (nullable = true)\n",
      " |-- Average_Household_Size: integer (nullable = true)\n",
      " |-- Black_Population: integer (nullable = true)\n",
      " |-- Hispanic_Population: integer (nullable = true)\n",
      " |-- White_Population: integer (nullable = true)\n",
      " |-- Asian_Population: integer (nullable = true)\n",
      " |-- Native_Population: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_demographics_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the i94 Labels - Country Codes Data\n",
    "\n",
    "- Strip spaces from Country_Id and Country\n",
    "- Convert Country_Id to numeric field\n",
    "- Create a Spark Dataframe/Table from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country_Id: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_mapping_df['Country_Id'] = country_mapping_df['Country_Id'].str.strip()\n",
    "country_mapping_df['Country'] = country_mapping_df['Country'].str.strip()\n",
    "country_mapping_df[\"Country_Id\"] = pd.to_numeric(country_mapping_df[\"Country_Id\"],downcast='float')\n",
    "\n",
    "cleaned_country_mapping_sdf = spark.createDataFrame(country_mapping_df)\n",
    "cleaned_country_mapping_sdf.printSchema()\n",
    "cleaned_country_mapping_sdf.createOrReplaceTempView(\"cleaned_country_mapping_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the i94 Labels - Port Data\n",
    "\n",
    "- Strip spaces from Port_Id and Port\n",
    "- Remove the entry with Null Value\n",
    "- Create a Spark Dataframe/Table from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Port_Id: string (nullable = true)\n",
      " |-- Port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_mapping_df['Port_Id'] = port_mapping_df['Port_Id'].str.strip()\n",
    "port_mapping_df['Port'] = port_mapping_df['Port'].str.strip()\n",
    "port_mapping_df = port_mapping_df[port_mapping_df.Port.notnull()]\n",
    "\n",
    "cleaned_port_mapping_sdf = spark.createDataFrame(port_mapping_df)\n",
    "cleaned_port_mapping_sdf.printSchema()\n",
    "cleaned_port_mapping_sdf.createOrReplaceTempView(\"cleaned_port_mapping_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the i94 Labels - Immigration Mode Data\n",
    "\n",
    "- Strip spaces from Mode_Id and Mode\n",
    "- Convert Mode_Id to numeric field\n",
    "- Create a Spark Dataframe/Table from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Mode_Id: double (nullable = true)\n",
      " |-- Mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_mode_df['Mode_Id'] = immigration_mode_df['Mode_Id'].str.strip()\n",
    "immigration_mode_df['Mode'] = immigration_mode_df['Mode'].str.strip()\n",
    "immigration_mode_df[\"Mode_Id\"] = pd.to_numeric(immigration_mode_df[\"Mode_Id\"],downcast='float')\n",
    "\n",
    "cleaned_immigration_mode_sdf = spark.createDataFrame(immigration_mode_df)\n",
    "cleaned_immigration_mode_sdf.printSchema()\n",
    "cleaned_immigration_mode_sdf.createOrReplaceTempView(\"cleaned_immigration_mode_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Clean the i94 Labels - State Code Data\n",
    "\n",
    "- Strip spaces from State_Id and State\n",
    "- Create a Spark Dataframe/Table from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State_Id: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_code_df['State_Id'] = state_code_df['State_Id'].str.strip()\n",
    "state_code_df['State'] = state_code_df['State'].str.strip()\n",
    "\n",
    "cleaned_state_code_sdf = spark.createDataFrame(state_code_df)\n",
    "cleaned_state_code_sdf.printSchema()\n",
    "cleaned_state_code_sdf.createOrReplaceTempView(\"cleaned_state_mapping_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "A star schema has been designed which consists of the following Fact and Dimension tables. The advantages of using a star schema design are:\n",
    "1. Query performance - Because a star schema database has a small number of tables and clear join paths, queries run faster than they do against an OLTP system.\n",
    "2. Load performance and administration - Structural simplicity also reduces the time required to load large batches of data into a star schema database. By defining facts and dimensions and separating them into different tables, the impact of a load operation is reduced. Dimension tables can be populated once and occasionally refreshed. You can add new facts regularly and selectively by appending records to a fact table.\n",
    "3. Built-in referential integrity - A star schema has referential integrity built in when data is loaded.\n",
    "4. Easily understood - A star schema is easy to understand and navigate, with dimensions joined only through the fact table. \n",
    "\n",
    "Fact Table:\n",
    " - ImmigrationDetails\n",
    " \n",
    "Dimention Tables:\n",
    " - CityDemographics\n",
    " - CountryDetails\n",
    " - PortCodes\n",
    " - ImmigrationMode\n",
    "\n",
    "\n",
    "<img src=\"Images/Data Model.png\">\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The above mentioned Fact and dimention tables are created by transforming the original data sources. This star schema is then written into parquet files using the function 'write_to_parquet_files'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create the Data Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### ImmigrationDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ImmigrationDetails = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    cast(cicid as bigint)    AS cicid\n",
    "    ,arrdate                 AS arrival_date\n",
    "    ,depdate                 AS departure_date\n",
    "    ,i94addr                 AS us_address\n",
    "    ,cast(i94res as int)     AS resident_country\n",
    "    ,cast(i94cit as int)     AS resident_city\n",
    "    ,cast(i94mode as int)    AS travel_mode\n",
    "    ,i94port                 AS port\n",
    "    ,cast(i94visa as int)    AS visa_code\n",
    "    ,cast(i94bir as int)     AS age\n",
    "    ,visatype                AS visa_type\n",
    "    ,biryear                 AS birth_year\n",
    "    ,gender                  AS gender\n",
    "    ,cast(admnum as bigint)  AS admission_number\n",
    "    ,airline                 AS airline\n",
    "    ,fltno                   AS flight_number\n",
    "    FROM cleaned_immigration_table\n",
    "    \"\"\")\n",
    "ImmigrationDetails.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### CityDemographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "CityDemographics = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "     State_Code               AS state_code\n",
    "    ,State                    AS state\n",
    "    ,City                     AS city\n",
    "    ,Median_Age               AS median_age\n",
    "    ,Average_Household_Size   AS average_household_size\n",
    "    ,Total_Population         AS total_population\n",
    "    ,Male_Population          AS male_population\n",
    "    ,Female_Population        AS female_population\n",
    "    ,Foreign_Born             AS foreign_born\n",
    "    ,Number_of_Veterans       AS veteran_population\n",
    "    ,Black_Population         AS black_population\n",
    "    ,Hispanic_Population      AS hispanic_population\n",
    "    ,White_Population         AS white_population\n",
    "    ,Asian_Population         AS asian_population\n",
    "    ,Native_Population        AS native_population              \n",
    "    FROM cleaned_demographics_table\n",
    "    \"\"\")\n",
    "CityDemographics.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### CountryDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create intermediate spark dataframe with aggregated values grouped by Country\n",
    "intermediate_CountryDetails = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "     Country\n",
    "    ,avg(cast(AverageTemperature as float)) AverageTemperature\n",
    "    ,first_value(latitude) as latitude\n",
    "    ,first_value(longitude) as longitude\n",
    "    FROM cleaned_temperature_table\n",
    "    GROUP BY \n",
    "    Country\n",
    "    \"\"\")\n",
    "intermediate_CountryDetails.createOrReplaceTempView(\"intermediate_CountryDetails_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- average_temperature: double (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      "\n",
      "+------------+------------+-------------------+--------+---------+\n",
      "|country_code|     country|average_temperature|latitude|longitude|\n",
      "+------------+------------+-------------------+--------+---------+\n",
      "|         151|     Armenia|   8.37559700012207|  40.99N|   44.73E|\n",
      "|         512|     Bahamas| 24.786977767944336|  24.92N|   78.03W|\n",
      "|         373|South Africa|  16.36072629928589|  26.52S|   26.87E|\n",
      "|         243|       Burma|   26.0009747505188|  21.70N|   96.06E|\n",
      "|         274|  Bangladesh|  25.05098473398309|  23.31N|   90.00E|\n",
      "+------------+------------+-------------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final Country Details dataframe after joining the data with Country code\n",
    "CountryDetails = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "     cast(C.Country_Id as int) AS country_code\n",
    "    ,T.Country                 AS country\n",
    "    ,T.AverageTemperature      AS average_temperature\n",
    "    ,T.latitude                AS latitude\n",
    "    ,T.longitude               AS longitude\n",
    "    FROM \n",
    "    cleaned_country_mapping_table C\n",
    "    ,intermediate_CountryDetails_table T\n",
    "    WHERE \n",
    "    C.Country=upper(T.Country)\n",
    "    \"\"\")\n",
    "CountryDetails.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### PortCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- port_code: string (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      "\n",
      "+---------+----------------------------+\n",
      "|port_code|port                        |\n",
      "+---------+----------------------------+\n",
      "|ALC      |ALCAN, AK                   |\n",
      "|ANC      |ANCHORAGE, AK               |\n",
      "|BAR      |BAKER AAF - BAKER ISLAND, AK|\n",
      "|DAC      |DALTONS CACHE, AK           |\n",
      "|PIZ      |DEW STATION PT LAY DEW, AK  |\n",
      "+---------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PortCodes = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "     Port_Id          AS port_code\n",
    "    ,Port             AS port    \n",
    "    FROM \n",
    "    cleaned_port_mapping_table\n",
    "    \"\"\")\n",
    "PortCodes.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### ImmigrationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mode_id: integer (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n",
      "+-------+------------+\n",
      "|mode_id|mode        |\n",
      "+-------+------------+\n",
      "|1      |Air         |\n",
      "|2      |Sea         |\n",
      "|3      |Land        |\n",
      "|9      |Not reported|\n",
      "+-------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImmigrationModes = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "     cast(Mode_Id as int) AS mode_id\n",
    "    ,Mode                 AS mode\n",
    "    FROM \n",
    "    cleaned_immigration_mode_table\n",
    "    \"\"\")\n",
    "ImmigrationModes.printSchema()\n",
    "ImmigrationModes.show(5,truncate=False)\n",
    "ImmigrationModes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Write to Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "path                     = config['LOCAL']['PATH']\n",
    "immigration_details_data = config['DATA']['IMMIGRATION_DATA']\n",
    "city_demographics_data   = config['DATA']['CITY_DEMOGRAPHICS_DATA']\n",
    "country_details_data     = config['DATA']['COUNTRY_DETAILS_DATA']\n",
    "port_codes_data          = config['DATA']['PORT_CODES_DATA']\n",
    "immigration_modes_data   = config['DATA']['IMMIGRATION_MODES_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_to_parquet_files(dataframe, name, full_path):\n",
    "    \"\"\"\n",
    "        This function writes the data stored in a Spark Dataframe in parquet format.\n",
    "        This function also logs the current Dataframe being processed, the path where\n",
    "        the parquet files are being written and the time taken to write the data.\n",
    "        \n",
    "        The input passed to this function are:\n",
    "        1. dataframe - Dataframe to written out to parquet files.\n",
    "        2. name - Name of the dataframe to display status.\n",
    "        3. full_path - Path where the parquet files are to be stored.\n",
    "        \n",
    "        \"\"\"     \n",
    "    print(\"\\nWriting {} to parquet files in {}\".format(name,full_path))\n",
    "    start_time = datetime.now()\n",
    "    dataframe.write.mode(\"overwrite\").parquet(full_path)\n",
    "    end_time = datetime.now()\n",
    "    print(\"{} written in {}.\".format(name,end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing ImmigrationDetails to parquet files in ./udacity-dend-rp/immigration_data/\n",
      "ImmigrationDetails written in 0:00:55.592554.\n",
      "\n",
      "Writing CityDemographics to parquet files in ./udacity-dend-rp/city_demographics_data/\n",
      "CityDemographics written in 0:00:08.809060.\n",
      "\n",
      "Writing CountryDetails to parquet files in ./udacity-dend-rp/country_details_data/\n",
      "CountryDetails written in 0:00:40.555483.\n",
      "\n",
      "Writing PortCodes to parquet files in ./udacity-dend-rp/port_codes_data/\n",
      "PortCodes written in 0:00:00.232835.\n",
      "\n",
      "Writing ImmigrationModes to parquet files in ./udacity-dend-rp/immigration_modes_data/\n",
      "ImmigrationModes written in 0:00:00.195931.\n"
     ]
    }
   ],
   "source": [
    "write_to_parquet_files(ImmigrationDetails, 'ImmigrationDetails', path+immigration_details_data) \n",
    "write_to_parquet_files(CityDemographics, 'CityDemographics', path+city_demographics_data) \n",
    "write_to_parquet_files(CountryDetails, 'CountryDetails', path+country_details_data) \n",
    "write_to_parquet_files(PortCodes, 'PortCodes', path+port_codes_data) \n",
    "write_to_parquet_files(ImmigrationModes, 'ImmigrationModes', path+immigration_modes_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quality check for ImmigrationDetails:\n",
      "No. of rows for ImmigrationDetails:3096074\n",
      "No. of null values primary key cicid:0\n",
      "Quality check passed. Time taken is 0:00:01.161392\n",
      "\n",
      "Quality check for CityDemographics:\n",
      "No. of rows for CityDemographics:596\n",
      "No. of null values primary key state_code:0\n",
      "Quality check passed. Time taken is 0:00:02.383112\n",
      "\n",
      "Quality check for CountryDetails:\n",
      "No. of rows for CountryDetails:149\n",
      "No. of null values primary key country_code:0\n",
      "Quality check passed. Time taken is 0:00:01.170871\n",
      "\n",
      "Quality check for PortCodes:\n",
      "No. of rows for PortCodes:660\n",
      "No. of null values primary key port_code:0\n",
      "Quality check passed. Time taken is 0:00:00.391623\n",
      "\n",
      "Quality check for ImmigrationModes:\n",
      "No. of rows for ImmigrationModes:4\n",
      "No. of null values primary key mode_id:0\n",
      "Quality check passed. Time taken is 0:00:00.329444\n"
     ]
    }
   ],
   "source": [
    "def quality_check(parquet_file, dataframe, primary_key):\n",
    "    \"\"\"\n",
    "        This function is to perform quality checks on the parquet files which have been\n",
    "        written. This function checks for:\n",
    "        i.  The number of entries in the parquet file.\n",
    "        ii. Number of NULL values for the primary key for the field in the dataframe.\n",
    "        \n",
    "        This function also logs the current parquet file being processed, the number of \n",
    "        entries, the number of entries with NULL values for the primary key field, the \n",
    "        time taken to perform the validation and whether the quality check has passed.\n",
    "        The Quality check passes if:\n",
    "        i.  There are more than zero entries.\n",
    "        ii. There are no NULL values for the primary key.\n",
    "        \n",
    "        The input passed to this function are:\n",
    "        1. parquet_file - The parquet file path.\n",
    "        2. dataframe - The name of the dataframe\n",
    "        3. primary_key - The primary key for the dataframe.\n",
    "        \n",
    "        \"\"\"    \n",
    "    start_time = datetime.now()\n",
    "    print(\"\\nQuality check for {}:\".format(dataframe))\n",
    "    parquet_df = spark.read.parquet(parquet_file)\n",
    "    row_count = parquet_df.count()\n",
    "    parquet_df.createOrReplaceTempView(\"parquet_table\")\n",
    "    pk_null_count = spark.sql(\"SELECT count(*) FROM parquet_table WHERE {} IS NULL\".format(primary_key)).collect()[0][0]\n",
    "    print(\"No. of rows for {}:{}\".format(dataframe,str(row_count)))\n",
    "    print(\"No. of null values primary key {}:{}\".format(primary_key,str(pk_null_count)))\n",
    "    end_time = datetime.now()\n",
    "    if(row_count>0 and pk_null_count==0):\n",
    "        print('Quality check passed. Time taken is {}'.format(end_time-start_time))\n",
    "    else:\n",
    "        print('Quality check failed. Time taken is {}'.format(end_time-start_time))\n",
    "\n",
    "quality_check(path+immigration_details_data,'ImmigrationDetails','cicid') \n",
    "quality_check(path+city_demographics_data,'CityDemographics','state_code') \n",
    "quality_check(path+country_details_data,'CountryDetails','country_code') \n",
    "quality_check(path+port_codes_data,'PortCodes','port_code')    \n",
    "quality_check(path+immigration_modes_data,'ImmigrationModes','mode_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "##### ImmigrationDetails (Fact Table)\n",
    "The main source of data for this table is the I94 Immigration Data. The data dictionary is provided below.\n",
    "\n",
    "| Field | Datatype|\n",
    "| --- | --- |\n",
    "| cicid\t\t\t\t| long \t   |\n",
    "| arrival_date\t\t| date \t   |\n",
    "| departure_date\t| date \t   |\n",
    "| us_address\t\t| string \t|\n",
    "| resident_country\t| integer  |\n",
    "| resident_city\t\t| integer  |\n",
    "| travel_mode\t\t| integer  |\n",
    "| port\t\t\t\t| string \t|\n",
    "| visa_code\t\t\t| integer  |\n",
    "| age\t\t\t\t| integer  |\n",
    "| visa_type\t\t\t| string \t|\n",
    "| birth_year\t\t| double \t|\n",
    "| gender\t\t\t| string \t|\n",
    "| admission_number\t| long \t   |\n",
    "| airline\t\t\t| string \t|\n",
    "| flight_number\t\t| string \t|\n",
    "\n",
    "\n",
    "##### CityDemographics (Dimension Table)\n",
    "The main source of data for this table is the U.S. City Demographic Data from OpenSoft. The data dictionary is provided below.\n",
    "\n",
    "| Field | Datatype|\n",
    "| --- | --- |\n",
    "| state_code\t\t\t | string  |\n",
    "| state\t\t\t\t\t | string  |\n",
    "| city\t\t\t\t\t | string  |\n",
    "| median_age\t\t\t | integer |\n",
    "| average_household_size | integer |\n",
    "| total_population\t\t | integer |\n",
    "| male_population\t\t | integer |\n",
    "| female_population\t\t | integer |\n",
    "| foreign_born\t\t\t | integer |\n",
    "| veteran_population\t | integer |\n",
    "| black_population\t\t | integer |\n",
    "| hispanic_population\t | integer |\n",
    "| white_population\t\t | integer |\n",
    "| asian_population\t\t | integer |\n",
    "| native_population\t\t | integer |\n",
    "\n",
    "\n",
    "##### CountryDetails (Dimension Table)\n",
    "The main source of data for this table is the Kaggle dataset for World Temperature Data and the country codes provided in the SAS file I94_SAS_Labels_Descriptions. The Kaggle dataset contained data for several years, this was aggregated based on the Country after joinig this with the Country Codes in the SAS file. The data dictionary is provided below.\n",
    "\n",
    "| Field | Datatype|\n",
    "| --- | --- |\n",
    "| country_code\t\t\t| integer |\n",
    "| country\t\t\t\t| string  |\n",
    "| average_temperature\t| double  |\n",
    "| latitude\t\t\t\t| string  |\n",
    "| longitude\t\t\t\t| string  |\n",
    "\n",
    "\n",
    "##### PortCodes (Dimension Table)\n",
    "The main source of data for this table is the SAS file I94_SAS_Labels_Descriptions. The data dictionary is provided below.\n",
    "\n",
    "| Field | Datatype|\n",
    "| --- | --- |\n",
    "| port_code\t\t| string |\n",
    "| port\t\t\t| string |\n",
    "\n",
    "\n",
    "##### ImmigrationModes (Dimension Table)\n",
    "The main source of data for this table is the SAS file I94_SAS_Labels_Descriptions. The data dictionary is provided below.\n",
    "\n",
    "| Field | Datatype|\n",
    "| --- | --- |\n",
    "| mode_id\t| integer |\n",
    "| mode\t\t| string  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "This project demonstrates the simplicity with which a Data Warehouse can be implemented with a few tools which have been proven to be very versatile and scalable. If required, this can easily be transformed into a cloud based solution which is low cost, scalable and highly reliable infrastructure platform. The tools which has been used here and it's advantages are provided below:\n",
    "\n",
    "- Python:\n",
    "        + Learning ease and support available\n",
    "        + Extensive support libraries\n",
    "        + Presence of third party modules\n",
    "        + Open Source and community development\n",
    "        + User friendly data structures\n",
    "        + Productivity and speed\n",
    "\n",
    "\n",
    "- Spark:\n",
    "        + Provides highly reliable fast in memory computation\n",
    "        + Efficient in interactive queries and iterative algorithm\n",
    "        + Highly efficent in real time analytics using spark streaming and spark sql\n",
    "        + Compatibilty with any api JAVA, SCALA, PYTHON, R makes programming easy\n",
    "\n",
    "\n",
    "- Pandas:\n",
    "        + Efficiently handles large data\n",
    "        + Made for Python\n",
    "        + Makes data flexible and customizable\n",
    "\n",
    "\n",
    "- Parquet files:\n",
    "        + These can be used in any Hadoop ecosystem like Hive, Impala, Pig and Spark.\n",
    "        + Organizing by column allows for better compression, as data is more homogeneous.\n",
    "        + The space savings are very noticeable at the scale of a Hadoop cluster.\n",
    "        + I/O will be reduced as we can efficiently scan only a subset of the columns while reading the data. \n",
    "        + Better compression also reduces the bandwidth required to read the input.\n",
    "\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "         + This solution can be easily scaled by moving it to the Amazon cloud which has the ability to scale without issues. The parquet files can also be loaded to Amazon Redshift databases which is very scalable.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "         + Airflow can be incorporated to handle the piplelines and run at customized schedules as well as populate dashboards as per the required schedules.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "         + As mentioned earlier, the data can be loaded into Amazon Redshift where nodes can be added and removed as required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
